<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>PointNet & PointNet++ — Research — Pradeep Bolleddu</title>

  <!-- Tailwind for quick layout -->
  <script src="https://cdn.tailwindcss.com"></script>

  <style>
    .term-title { font-weight: 700; color: #0f172a; }
    .kbd { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, "Roboto Mono", monospace; background:#f8fafc; padding:0.1rem 0.35rem; border-radius:4px; }
    pre.code { background:#0f172a; color:#e6eef6; padding:1rem; border-radius:8px; overflow:auto; }
    .diagram-label { font-family: "Roboto Mono", monospace; font-size:13px; fill:#0f172a; }
    .svg-point { fill: #06b6d4; stroke: #0369a1; stroke-width:0.6px; }
    .svg-edge { stroke: #94a3b8; stroke-width:1px; }
    .svg-mlp { fill:#f0f9ff; stroke:#0891b2; stroke-width:1px; }
  </style>
</head>
<body class="bg-slate-50 text-slate-800 antialiased">
  <header class="bg-white border-b border-slate-200">
    <div class="max-w-5xl mx-auto px-6 py-5 flex items-center justify-between gap-4">
      <div>
        <a href="index.html" class="text-slate-700 hover:text-slate-900 font-semibold">&larr; Back to Research Index</a>
      </div>
      <h1 class="text-lg font-extrabold">PointNet & PointNet++</h1>
      <div class="text-sm text-slate-500">Pradeep Bolleddu — Research Notes</div>
    </div>
  </header>

  <main class="max-w-5xl mx-auto px-6 py-8 space-y-8">
    <!-- Overview -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-2">Overview</h2>
      <p class="text-slate-700">PointNet (Qi et al., 2017) introduced a simple, effective neural architecture that directly consumes point clouds (unordered sets of 3D points). It enforces permutation invariance using a symmetric function (max pooling) and processes each point independently with shared MLPs. PointNet++ builds on this by hierarchically applying PointNet to local neighborhoods, capturing local structure and geometric context.</p>
    </section>

    <!-- Diagram -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-4">Architecture diagram (visual)</h2>
      <p class="text-sm text-slate-600 mb-4">Inline SVG: input point cloud → per-point MLP (shared) → symmetric aggregation (max pooling) → global features → classification head. For PointNet++ you see hierarchical grouping and local PointNet modules.</p>

      <div class="flex flex-col md:flex-row gap-6 items-start">
        <div class="md:flex-1">
          <svg viewBox="0 0 920 380" class="w-full bg-white rounded-md p-2" role="img" aria-label="PointNet architecture">
            <!-- Point cloud -->
            <g transform="translate(20,20)">
              <!-- cloud of points -->
              <rect x="0" y="0" width="220" height="220" rx="8" fill="#f8fafc" stroke="#cfeff6"></rect>
              <text x="8" y="14" class="diagram-label">Input point cloud (N x 3) + optional features</text>
              <!-- many small points -->
              <g transform="translate(10,30)">
                <!-- row of points -->
                <circle cx="12" cy="12" r="4" class="svg-point"/>
                <circle cx="40" cy="18" r="4" class="svg-point"/>
                <circle cx="70" cy="8" r="4" class="svg-point"/>
                <circle cx="100" cy="28" r="4" class="svg-point"/>
                <circle cx="130" cy="18" r="4" class="svg-point"/>
                <circle cx="160" cy="12" r="4" class="svg-point"/>
                <circle cx="190" cy="22" r="4" class="svg-point"/>
                
                <circle cx="22" cy="52" r="4" class="svg-point"/>
                <circle cx="52" cy="46" r="4" class="svg-point"/>
                <circle cx="82" cy="66" r="4" class="svg-point"/>
                <circle cx="112" cy="56" r="4" class="svg-point"/>
                <circle cx="142" cy="62" r="4" class="svg-point"/>
                <circle cx="172" cy="50" r="4" class="svg-point"/>
                <circle cx="192" cy="62" r="4" class="svg-point"/>
                
                <circle cx="32" cy="92" r="4" class="svg-point"/>
                <circle cx="62" cy="102" r="4" class="svg-point"/>
                <circle cx="92" cy="86" r="4" class="svg-point"/>
                <circle cx="122" cy="96" r="4" class="svg-point"/>
                <circle cx="152" cy="86" r="4" class="svg-point"/>
                <circle cx="182" cy="90" r="4" class="svg-point"/>
              </g>
            </g>

            <!-- arrows to shared MLP -->
            <g transform="translate(250, 60)">
              <line x1="0" y1="40" x2="60" y2="40" class="svg-edge"/>
              <text x="70" y="36" class="diagram-label">shared MLP (per-point)</text>
            </g>

            <!-- MLP block -->
            <g transform="translate(360,30)">
              <rect x="0" y="0" width="180" height="140" rx="8" class="svg-mlp"></rect>
              <text x="12" y="20" class="diagram-label">Shared MLP (fc -> relu -> fc...)</text>
              <text x="12" y="48" class="diagram-label" style="font-size:12px">Per-point feature f_i = h(x_i)</text>

              <!-- small layer boxes -->
              <g transform="translate(110,36)">
                <rect x="0" y="0" width="56" height="18" rx="4" fill="#e6f6ff" stroke="#0369a1"></rect>
                <rect x="0" y="26" width="56" height="18" rx="4" fill="#e6f6ff" stroke="#0369a1"></rect>
                <rect x="0" y="52" width="56" height="18" rx="4" fill="#e6f6ff" stroke="#0369a1"></rect>
              </g>
            </g>

            <!-- arrow to symmetric pooling -->
            <g transform="translate(560,60)">
              <line x1="0" y1="40" x2="60" y2="40" class="svg-edge"/>
              <rect x="68" y="6" width="90" height="66" rx="6" fill="#fff7ed" stroke="#f59e0b"></rect>
              <text x="74" y="30" class="diagram-label">Symmetric aggregation</text>
              <text x="74" y="48" class="diagram-label" style="font-size:12px">maxpool across points → global feature g</text>
            </g>

            <!-- global feature leading to FC heads -->
            <g transform="translate(660, 30)">
              <rect x="0" y="0" width="200" height="120" rx="8" fill="#f8fafc" stroke="#c7f9ff"></rect>
              <text x="12" y="22" class="diagram-label">Global feature g (classification / segmentation heads)</text>
              <text x="12" y="46" class="diagram-label" style="font-size:12px">Classification: fc -> softmax</text>
              <text x="12" y="66" class="diagram-label" style="font-size:12px">Segmentation: concat per-point features + global -> per-point FC</text>
            </g>

            <!-- PointNet++ local grouping inset -->
            <g transform="translate(18,260)">
              <rect x="0" y="0" width="880" height="96" rx="8" fill="#fff" stroke="#e6eef6"></rect>
              <text x="8" y="18" class="diagram-label">PointNet++: hierarchical set abstraction</text>
              <text x="8" y="36" class="diagram-label" style="font-size:12px">sample points → group local neighborhoods → apply small PointNet to each group → aggregate → repeat (multi-scale)</text>
            </g>
          </svg>
        </div>

        <div class="md:w-80 bg-slate-50 border border-slate-100 rounded p-4">
          <h4 class="text-sm font-semibold mb-2">Quick facts</h4>
          <ul class="text-sm space-y-2 text-slate-700">
            <li><span class="font-semibold">Input:</span> unordered point cloud (N × (x,y,z) ± normals, colors)</li>
            <li><span class="font-semibold">Core idea:</span> shared MLPs + symmetric pooling for permutation invariance</li>
            <li><span class="font-semibold">PointNet++:</span> hierarchical local feature learning via sampling & grouping</li>
            <li><span class="font-semibold">Use-cases:</span> classification, part segmentation, scene segmentation, registration</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Definitions & Concepts -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-4">Definitions & Core Concepts</h2>
      <dl class="space-y-4">
        <div>
          <dt class="term-title">Point cloud</dt>
          <dd class="text-slate-700">A set of points in 3D space, typically represented as N × 3 coordinates (x,y,z). Points may include extra attributes such as normals, color (RGB), or intensity.</dd>
        </div>

        <div>
          <dt class="term-title">Permutation invariance</dt>
          <dd class="text-slate-700">The network's output should not depend on the order of input points. PointNet enforces this using a symmetric function (max pooling) across per-point features.</dd>
        </div>

        <div>
          <dt class="term-title">Symmetric function</dt>
          <dd class="text-slate-700">A function g over a set that is invariant to permutations of its inputs. Common choices: max, sum, average. PointNet uses max to capture salient features.</dd>
        </div>

        <div>
          <dt class="term-title">Local neighborhood / set abstraction</dt>
          <dd class="text-slate-700">PointNet++ samples a set of centroids and groups points within radius r (or k-nearest) to capture local geometry; a local PointNet processes each group to produce a higher-level descriptor.</dd>
        </div>

        <div>
          <dt class="term-title">Feature learning</dt>
          <dd class="text-slate-700">Shared MLP learns per-point features; global pooling aggregates these into a global descriptor suitable for tasks like classification. For segmentation, per-point features are concatenated with global context.</dd>
        </div>
      </dl>
    </section>

    <!-- Equations -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-3">Key Equations</h2>
      <div class="text-sm text-slate-700 space-y-3">
        <div>
          <strong>Per-point mapping:</strong> h: ℝ³ → ℝ^K, f_i = h(x_i), where h is a shared MLP.
        </div>
        <div>
          <strong>Symmetric aggregation (global feature):</strong>
          <pre class="code"><code>g = MAX_{i=1..N} f_i</code></pre>
          (MAX denotes element-wise maximum across the N per-point feature vectors.)
        </div>
        <div>
          <strong>Permutation-invariant function (learned):</strong>
          <pre class="code"><code>F({x_i}) = γ ( MAX_i ( φ(x_i) ) )</code></pre>
          where φ and γ are MLPs (φ = per-point encoder, γ = classifier / aggregator).
        </div>
      </div>
    </section>

    <!-- Pseudocode -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-3">PyTorch-like pseudocode (PointNet)</h2>

      <pre class="code"><code>class PointNet(nn.Module):
    def __init__(self, emb_dims=1024, num_classes=40):
        super().__init__()
        self.mlp1 = nn.Sequential(nn.Linear(3,64), nn.ReLU(), nn.Linear(64,128), nn.ReLU(), nn.Linear(128,emb_dims))
        self.classifier = nn.Sequential(nn.Linear(emb_dims,512), nn.ReLU(), nn.Dropout(0.3),
                                        nn.Linear(512,256), nn.ReLU(), nn.Dropout(0.3),
                                        nn.Linear(256,num_classes))

    def forward(self, x):  # x: B x N x 3
        B, N, _ = x.shape
        x = x.view(B*N, 3)
        f = self.mlp1(x)            # (B*N, emb_dims)
        f = f.view(B, N, -1)        # (B, N, emb_dims)
        g = torch.max(f, dim=1)[0]  # global feature (B, emb_dims)
        logits = self.classifier(g)
        return logits</code></pre>

      <h3 class="text-lg font-semibold mt-4">PointNet++ sketch</h3>
      <p class="text-slate-700">PointNet++ adds: (1) sampling (farthest point sampling) to select centroids, (2) grouping (radius or kNN) to build local neighborhoods, (3) apply a small PointNet to each group to learn local descriptors, and (4) hierarchically repeat.</p>
    </section>

    <!-- Datasets & Evaluation -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-3">Datasets, evaluation & practical tips</h2>
      <div class="text-slate-700 space-y-3">
        <p><strong>Common datasets:</strong> ModelNet40 (object classification), ShapeNetPart (part segmentation), S3DIS / ScanNet (indoor scene segmentation), KITTI / SemanticKITTI (LiDAR segmentation), ScanObjectNN (real scanned objects).</p>

        <p><strong>Metrics:</strong> classification accuracy; segmentation: IoU (per-class), mean IoU (mIoU), mAcc; for detection/semantic labeling use AP or per-point accuracy.</p>

        <p><strong>Practical tips:</strong>
          <ul class="list-disc pl-5 mt-2">
            <li>Normalize point clouds (center & scale to unit sphere) during preprocessing.</li>
            <li>Use random rotation (around z for indoor/oriented objects) and jittering for augmentation.</li>
            <li>Train with random subsampling of points (e.g., N=1024 or 2048) to mimic sensor sparsity.</li>
            <li>Use batch normalization in MLPs and careful learning-rate scheduling.</li>
            <li>Experiment with symmetric functions (max, avg, sum) — max often works best for capturing distinctive features.</li>
          </ul>
        </p>
      </div>
    </section>

    <!-- Variants & Extensions -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-3">Variants & notable extensions</h2>
      <ul class="list-disc pl-5 text-slate-700 space-y-2">
        <li><strong>PointNet++:</strong> hierarchical grouping and local PointNet encoders to capture fine-grained geometry.</li>
        <li><strong>Dynamic Graph CNN (DGCNN):</strong> uses edgeConv and dynamically computed neighborhoods for graph features.</li>
        <li><strong>PointCNN:</strong> learns X-transforms to permute points into canonical order for convolutions.</li>
        <li><strong>KPConv / PointConv:</strong> continuous convolution operators on point clouds using kernel functions.</li>
        <li><strong>RandLA-Net, PVCNN, RandLA:</strong> efficient/large-scale point cloud processing strategies for scene-level tasks.</li>
      </ul>
    </section>

    <!-- References & links -->
    <section class="bg-white rounded-xl shadow p-6">
      <h2 class="text-xl font-bold mb-3">References & further reading</h2>
      <div class="text-sm text-slate-700 space-y-2">
        <ul class="list-disc pl-5 mt-2">
          <li><a class="text-blue-600 hover:underline" href="https://arxiv.org/abs/1612.00593" target="_blank" rel="noopener noreferrer">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation — Qi et al., 2017 (arXiv)</a></li>
          <li><a class="text-blue-600 hover:underline" href="https://arxiv.org/abs/1706.02413" target="_blank" rel="noopener noreferrer">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space — Qi et al., 2017 (arXiv)</a></li>
          <li><a class="text-blue-600 hover:underline" href="https://github.com/charlesq34/pointnet" target="_blank" rel="noopener noreferrer">PointNet original GitHub implementations / examples</a></li>
          <li><a class="text-blue-600 hover:underline" href="https://github.com/erikwijmans/Pointnet2_PyTorch" target="_blank" rel="noopener noreferrer">PointNet++ PyTorch reimplementations</a></li>
        </ul>
      </div>

      <p class="text-xs text-slate-500 mt-4">Tip: if you have local PDFs for these papers, place them in this `research/` folder and reference them as <span class="kbd">./pointnet.pdf</span> and <span class="kbd">./pointnet2.pdf</span> — this will keep everything inside the same domain.</p>
    </section>

    <!-- CTA -->
    <section class="text-center text-sm text-slate-600">
      <p>Want a printable cheat-sheet, an interactive demo (WebGL viewer for point clouds), or a mini-tutorial Jupyter notebook to reproduce ModelNet40 results? I can add those files to this same folder and link them from here.</p>
    </section>
  </main>

  <footer class="bg-white border-t border-slate-200 mt-10">
    <div class="max-w-5xl mx-auto px-6 py-6 text-xs text-slate-500">
      © <span id="year-footer"></span> Pradeep Bolleddu — PointNet notes. <a href="index.html" class="ml-3 text-slate-600 hover:underline">Research index</a>
    </div>
  </footer>

  <script>
    document.getElementById('year-footer').textContent = new Date().getFullYear();
  </script>
</body>
</html>

